{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2f803df-c23a-439d-909a-378049b1869f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#define functions needed to create lifetables for men and women for year <year> over months 1-<month>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94766bd7-38df-4165-83ba-ba5b1de89d86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def makelifetable(sample, year):\n",
    "\n",
    "    #filter only those who were members in given year\n",
    "    #for our purposes this means just removing those who died before <year>\n",
    "    sample = sample.withColumn('death_year', spark_funcs.year('date_of_death'))\n",
    "    sample = sample.filter( ~( (spark_funcs.col('death_indicator') == spark_funcs.lit(True)) & (spark_funcs.col('death_year') < spark_funcs.lit(year)) ) )\n",
    "\n",
    "    #find age at jan 1 of year\n",
    "    comp_str = str(year) + '-01-01'\n",
    "    sample = sample.withColumn('age_comp', spark_funcs.to_date(spark_funcs.lit(comp_str)))\n",
    "    sample = sample.withColumn('age_jan_year', spark_funcs.floor(spark_funcs.months_between(spark_funcs.col('age_comp'), spark_funcs.col(\"date_of_birth\"))/spark_funcs.lit(12)))\n",
    "\n",
    "\n",
    "    #create living, dead roster\n",
    "    living = sample.groupBy(['age_jan_year', 'gender']).count().sort(['age_jan_year', 'gender']).withColumnRenamed('count', 'alive_jan1')\n",
    "    dead = sample.filter((spark_funcs.col('death_indicator') == spark_funcs.lit(True)) & (spark_funcs.col('death_year') == spark_funcs.lit(year))).groupBy(['age_jan_year', 'gender']).count().sort(['age_jan_year', 'gender']).withColumnRenamed('count', 'died')\n",
    "\n",
    "    #create blank data frame to ensure all ages and genders represented in final output (useful if there would be 0 Men age 102, for example)\n",
    "    data = []\n",
    "    for x in range(60, 104):\n",
    "        data.append([x, 'F'])\n",
    "        data.append([x, 'M'])\n",
    "    \n",
    "    columns = [\"age_jan_year\", \"gender\"]\n",
    "    complete_ages = spark.createDataFrame(data, columns)\n",
    "    complete_ages = complete_ages.join(living, on=['age_jan_year', 'gender'], how='left')\n",
    "    complete_ages = complete_ages.join(dead, on=['age_jan_year', 'gender'], how='left')\n",
    "\n",
    "    #if no living in row, make living and dead = 1\n",
    "    #if no dead in row, make dead = 0\n",
    "    complete_ages = complete_ages.withColumn(\"died\", spark_funcs.when(spark_funcs.col('alive_jan1').isNull(), 1).otherwise(spark_funcs.col('died')))\n",
    "    complete_ages = complete_ages.withColumn(\"alive_jan1\", spark_funcs.when(spark_funcs.col('alive_jan1').isNull(), 1).otherwise(spark_funcs.col('alive_jan1')))\n",
    "    complete_ages = complete_ages.withColumn(\"died\", spark_funcs.when(spark_funcs.col('died').isNull(), 1).otherwise(spark_funcs.col('died')))\n",
    "\n",
    "\n",
    "    #Create in age death rate\n",
    "    complete_ages = complete_ages.withColumn('q', spark_funcs.col('died') / spark_funcs.col('alive_jan1'))\n",
    "\n",
    "    men = complete_ages.filter(spark_funcs.col('gender') == spark_funcs.lit('M'))\n",
    "    women = complete_ages.filter(spark_funcs.col('gender') == spark_funcs.lit('F'))\n",
    "\n",
    "    df_dict = {'men': men, 'women': women}\n",
    "\n",
    "    #Loop over genders to create final output\n",
    "    for x in range(0,2):\n",
    "        temp_df = df_dict[list(df_dict)[x]]\n",
    "        #assert order here\n",
    "        temp_df = temp_df.orderBy('age_jan_year')\n",
    "\n",
    "        #create I\n",
    "        temp_df = temp_df.withColumn( 'I', spark_funcs.when( spark_funcs.col('age_jan_year') == spark_funcs.lit(60), 100000).otherwise(0))\n",
    "        collected = temp_df.collect()\n",
    "        old_q = collected[0].__getitem__('q')\n",
    "        old_I = 100000\n",
    "        for i in range(60, 104):\n",
    "\n",
    "            old_I =  max(0, round(old_I*(1-old_q)))\n",
    "            if i < 103:\n",
    "                old_q = collected[i-59].__getitem__('q')\n",
    "            temp_df = temp_df.withColumn( 'I', spark_funcs.when( spark_funcs.col('age_jan_year') == spark_funcs.lit(i+1), old_I).otherwise(spark_funcs.col('I')))\n",
    "\n",
    "        #Create D\n",
    "        temp_df = temp_df.withColumn( 'D', spark_funcs.when( spark_funcs.col('age_jan_year') == spark_funcs.lit(103), spark_funcs.col('I')).otherwise(0))\n",
    "        collected = temp_df.collect()\n",
    "        for i in range(42, -1, -1):\n",
    "            old_I = collected[i+1].__getitem__('I')\n",
    "            curr_I = collected[i].__getitem__('I')\n",
    "            temp_df = temp_df.withColumn( 'D', spark_funcs.when( spark_funcs.col('age_jan_year') == spark_funcs.lit(i+60), curr_I - old_I).otherwise(spark_funcs.col('D')))\n",
    "\n",
    "\n",
    "        #Create LY\n",
    "        temp_df = temp_df.withColumn('LY', spark_funcs.col('I') - 0.5*spark_funcs.col('D'))\n",
    "\n",
    "        #Create TY\n",
    "        temp_df = temp_df.withColumn( 'TY', spark_funcs.when( spark_funcs.col('age_jan_year') == spark_funcs.lit(103), spark_funcs.col('LY')).otherwise(0))\n",
    "        collected = temp_df.collect()\n",
    "        old_TY = collected[43].__getitem__('TY')\n",
    "        for i in range(42, -1, -1):\n",
    "            old_TY = old_TY + collected[i].__getitem__('LY')\n",
    "            temp_df = temp_df.withColumn( 'TY', spark_funcs.when( spark_funcs.col('age_jan_year') == spark_funcs.lit(i+60), old_TY ).otherwise(spark_funcs.col('TY')))\n",
    "\n",
    "        #Create LE\n",
    "        temp_df = temp_df.withColumn( 'LE', spark_funcs.when( spark_funcs.col('I') > spark_funcs.lit(0), spark_funcs.col('TY') / spark_funcs.col('I')).otherwise(0))\n",
    "\n",
    "        #display output for download\n",
    "        display(temp_df.sort(\"age_jan_year\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dfb88dc-a1d1-4f6b-8fe8-58a6c5c879d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lifetable_functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
